{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/schwallergroup/ai4chem_course/blob/main/notebooks/04%20-%20Unsupervised%20Learning/DimensionalityReduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 tutorial 1 - AI 4 Chemistry\n",
    "\n",
    "## Table of content\n",
    "\n",
    "1. Unsupervised learning: dimensionality reduction\n",
    "2. PCA\n",
    "3. t-SNE\n",
    "4. TMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Relevant packages\n",
    "\n",
    "### Scikit-learn\n",
    "We will use again the `scikit-learn` package, which contains the `PCA` and `TSNE` methods that we will implement.\n",
    "\n",
    "### TMAP\n",
    "`TMAP` is a powerful visualization method capable of representing high-dimensional datasets as a 2D-tree. It can be applied in different domains apart from Chemistry. If you want to know more, you can check the original [paper](https://jcheminf.biomedcentral.com/articles/10.1186/s13321-020-0416-x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first install the necessary libraries and get the corresponding dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install usual data science libraries\n",
    "!pip install numpy scipy matplotlib scikit-learn pandas rdkit seaborn plotly\n",
    "\n",
    "#Install tmap\n",
    "!pip install tmap-viz\n",
    "\n",
    "#Download ESOL dataset\n",
    "!mkdir data/\n",
    "!wget https://raw.githubusercontent.com/schwallergroup/ai4chem_course/main/notebooks/04%20-%20Unsupervised%20Learning/data/esol.csv -O data/esol.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. - Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Dimensionality reduction` is a fundamental concept in unsupervised learning that aims to reduce the number of features or variables in high-dimensional datasets while preserving the most relevant information. This technique is particularly relevant when dealing with large and complex datasets with a high number of features in common. Besides, it can help scientists to better understand the underlying structure and relationships in their data. Here are some of the most common methods in dimensionality reduction:\n",
    "\n",
    "    - PCA (Principal Component Analysis)\n",
    "    - t-SNE (t-distributed Stochastic Neighbor Embedding) \n",
    "    - NMF (Non-Negative Matrix Factorization)\n",
    "    - UMAP (Uniform Manifold Approximation and Projection)\n",
    "\n",
    "By reducing the dimensionality of the data, it is also possible to visualize and interpret the data more easily, and to develop more efficient and accurate predictive models. In this notebook we will explore some dimensionality reduction methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " [PCA](https://towardsdatascience.com/principal-component-analysis-pca-explained-visually-with-zero-math-1cbf392b9e7d) (`Principal Component Analysis`) is a popular unsupervised learning technique used for dimensionality reduction. It aims to transform high-dimensional data into a lower-dimensional space while preserving the most important information by identifying the principal components of the data. PCA is widely used in data analysis, visualization, and feature extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1: ESOL dataset dimensionality reduction with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will apply PCA to the 2048-dimensional fingerprints representing the molecules in the ESOL dataset. We will try to reduce this space to 2 dimensions and plot the resulting space. Normally, before applying PCA you have to standardize your data, but in this case it is not necessary as we use binary features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import PandasTools\n",
    "import numpy as np\n",
    "\n",
    "#Load ESOL\n",
    "esol = pd.read_csv('data/esol.csv')\n",
    "\n",
    "### YOUR CODE #####\n",
    "\n",
    "#Create a 'Molecule' column containing rdkit.Mol from each molecule\n",
    "\n",
    "\n",
    "#Create Morgan fingerprints (r=2, nBits=2048) from Molecule column using apply()\n",
    "####\n",
    "\n",
    "esol.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we apply the `PCA` decomposition. You can check the documentation of the method [here](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html#sklearn.decomposition.PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "#### YOUR CODE ####\n",
    "\n",
    "#create PCA object with n=2\n",
    "\n",
    "\n",
    "#Create a numpy array containing the fingerprints\n",
    "\n",
    "#Apply the fit_transform method to the previous array and store it in coordinates\n",
    "\n",
    "#Add PC1 and PC2 values to each row \n",
    "\n",
    "####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the data using PC1 and PC2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.scatterplot(data=esol, x='PC1', y='PC2')\n",
    "\n",
    "plt.title('ESOL PCA plot');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will create a special category of labels to add to this plot. The labels will represent solubility categories. For the sake of simplicity, we will create 3 categories:\n",
    "\n",
    "    - Low: log solubility lower than -5\n",
    "    - Medium: log solubility between -5 and -1\n",
    "    - High: log solubility higher than -1\n",
    "\n",
    "The only purpose of this classification is adding more information to the plot, so you can explore different interpretations of the reduced space you are representing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function to add labels\n",
    "def solubility_class(log_sol):\n",
    "    '''Return the corresponding label according to solubility value\n",
    "    '''\n",
    "    if log_sol < -5:\n",
    "        return 'Low'\n",
    "    \n",
    "    elif log_sol > -1:\n",
    "        return 'High'\n",
    "        \n",
    "    else:\n",
    "        return 'Medium'\n",
    "\n",
    "\n",
    "### YOUR CODE ####\n",
    "\n",
    "#Add labels to the ESOL dataset by applying the previous function\n",
    "\n",
    "\n",
    "#Create the PCA plot again including the new labels\n",
    "\n",
    "\n",
    "#####\n",
    "plt.title('ESOL PCA plot with solubility label');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the label categories are quite mixed, and the plot do not clearly show a trend in our data. However, you may keep trying different visualizations (for example, you could add another dimension to the plot by including the PC3 and try to see if a 3D representation gives more information)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`t-distributed Stochastic Neighbor Embedding` (t-SNE). In contrast to PCA, t-SNE is able to separate nonlinear data, and it can be therefore more powerful to capture local structures and identify clusters of data points with similar features. However, it is computationally more expensive than PCA and it may not be suitable for very large datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2: ESOL dataset dimensionality reduction with t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following example, we will apply t-SNE to the previous dataset and compare the result to PCA decomposition. You can check the documentation [here](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "### YOUR CODE ####\n",
    "#Create a tsne object with n_components=2 and random_state=42. The latter parameter is used to ensure \n",
    "#reproducibility (this is a non-deterministic algorithm)\n",
    "\n",
    "\n",
    "#get the fp array\n",
    "\n",
    "\n",
    "#apply fit_transform() to the data\n",
    "\n",
    "\n",
    "#create columns with the tSNE coordinates in the original df\n",
    "\n",
    "\n",
    "#####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, plot the results including the solubility label and compare them to the PCA plot. Do you observe differences between the algorithms?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE ####\n",
    "\n",
    "\n",
    "####\n",
    "plt.title('ESOL t-SNE plot');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TMAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will use TMAP for visualizing our solubility dataset. A TMAP plot is constructed in 4 phases:\n",
    "\n",
    "    1. LSH forest indexing: data are indexed in an LSH forest data structure \n",
    "    2. kNN Graph Generation: data are clustered using a c-approximate kNN graph\n",
    "    3. MST Computation: a Minimum Spanning Tree is calculated\n",
    "    4. Layout generation of the MST\n",
    "\n",
    "The corresponding representation displays the data as a tree in 2D, showing the relationships between the different points not only through the presence of clusters but also through the branches of the tree.\n",
    "\n",
    "<div align=\"left\">\n",
    "<img src=\"img/TMAP.png\" width=\"400\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show how to create a simple visualization of our data via TMAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmap as tm\n",
    "\n",
    "#get fingerprints of molecules\n",
    "fps = esol['fp'].values\n",
    "\n",
    "#Transform fingerprints into tmap vectors\n",
    "vec_fp = [tm.VectorUchar(fp) for fp in fps]\n",
    "\n",
    "#Create MinHash encoder and LSH Forest\n",
    "enc = tm.Minhash(512)\n",
    "lf = tm.LSHForest(512, 128)\n",
    "\n",
    "#add vec_fp to minhash encoder and then pass it to the LSH forest\n",
    "lf.batch_add(enc.batch_from_binary_array(vec_fp))\n",
    "lf.index()\n",
    "\n",
    "# Configuration for the tmap layout\n",
    "CFG = tm.LayoutConfiguration()\n",
    "CFG.node_size = 1 / 50\n",
    "\n",
    "#Compute graph\n",
    "x, y, s, t, _ = tm.layout_from_lsh_forest(lf, CFG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have computed the graph, you can plot it. In our case, we use matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create figure\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "\n",
    "#Create a class to convert solubility class to integers \n",
    "def solubility_class_to_int(log_sol):\n",
    "    '''Return the corresponding label according to solubility value\n",
    "    '''\n",
    "    if log_sol < -5:\n",
    "        return 0\n",
    "    \n",
    "    elif log_sol > -1:\n",
    "        return 1\n",
    "        \n",
    "    else:\n",
    "        return 2\n",
    "\n",
    "#apply previous function (we create an array that will be used in the plotting function)\n",
    "esol['int_class'] = esol['log solubility (mol/L)'].apply(solubility_class_to_int)\n",
    "\n",
    "\n",
    "#Plot edges\n",
    "for i in range(len(s)):\n",
    "        plt.plot(\n",
    "            [x[s[i]], x[t[i]]],\n",
    "            [y[s[i]], y[t[i]]],\n",
    "            \"k-\",\n",
    "            linewidth=0.5,\n",
    "            alpha=0.5,\n",
    "            zorder=1,\n",
    "        )\n",
    "\n",
    "#Plot the vertices\n",
    "scatter = ax.scatter(x, y, c=esol['int_class'].values, cmap='Set1', s=2, zorder=2)\n",
    "plt.tight_layout()\n",
    "classes = ['High', 'Medium', 'Low']\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=classes)\n",
    "plt.title('ESOL TMAP visualization')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, you can use other libraries like [plotly](https://plotly.com/python-api-reference/index.html) or [Faerun](https://github.com/reymond-group/faerun) to plot the data in a more interactive mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example using plotly\n",
    "import plotly.express as px\n",
    "\n",
    "fig = px.scatter(x=x, y=y, color=esol['sol_class'].values,\n",
    "                  hover_name=esol['smiles'].values, color_continuous_scale=['#FF0000','#4169E1','#2E8B57'], title='ESOL TMAP')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We recommend you to check the original [repo](https://github.com/reymond-group/tmap) to observe the different possibilities of applying TMAP. Cheers to [Daniel Probst](https://github.com/daenuprobst) for creating this great tool!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1be16fbddf550357e4e46540ee01bc6d12a48d7bc56fc8427cd30121d5943dc8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
